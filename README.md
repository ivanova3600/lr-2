# Лабораторная работа №1

### Введение
В ходе данной лабораторной работы необходимо реализовать следующие алгоритмы машинного обучения: Linear/ Logistic Regression, SVM, KNN, Naive Bayes в отдельных классах. Также нужно настроить параметры моделей с помощью GridSeachSV или RandomSearchCV, организовать весь процесс с помощью Pipeline. Аналогично проделать с помощью коробочных решений. Также оценить полученные модели.  
### Ход работы
1) Линейная регрессия (с градиентным спуском)  
Гиперпараметры - lr (скорость обучения) и epoch (количество эпох).  
Модель: $$ X*w + b = Y $$  
'''
'''
weight - веса, b - шум, их инициализируем нулями. Во время обучения мы подбираем такие w и b, чтобы модель давала правильные ответы: сначала мы вычисляем y_pred по формуле выше. Далее мы вычисляем функцию потерь $1/(2*n)*\sum_{i=0}^{n} (y_pred-y)^2$:  
'''
np.sum(np.square(y_pred-y))/(2*self.m)
'''
self.m - длина входного массива, y - выходные точные данные, y_pred - предсказанные выходные данные. Далее находим градиенты:
'''
h = np.dot(X, self.w)+self.b
dw = np.dot(X.T,(h-y)) / self.m
db = np.sum(h-y)  / self.m
'''
